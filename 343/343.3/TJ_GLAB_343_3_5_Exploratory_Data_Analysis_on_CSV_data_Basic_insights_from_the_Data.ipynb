{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Guided LAB 343.3.5 - Exploratory Data Analysis on CSV data - Basic insights from the Data**\n",
        "---\n"
      ],
      "metadata": {
        "id": "JsLHgrOmtSbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lab Overview**\n",
        "\n",
        "This lab focuses on introducing fundamental data analysis techniques using Python's Pandas library. We'll primarily work with a CSV file containing employee data, exploring various methods to load, manipulate, and gain insights from it.\n",
        "\n",
        "In this lab, we will demonstrate how to read a CSV file with or without a header, skip rows, skip columns, set columns to index, and many more with examples. And we will perform Exploratory Data Analysis EDA on a CSV file.\n",
        "\n",
        "**Key Activities:**\n",
        "\n",
        "1. **Data Loading and Initial Exploration:**  We'll begin by importing the Pandas library and utilizing the `read_csv()` function to load the employee dataset into a Pandas DataFrame. We'll then use methods like `head()`, `tail()`, and `info()` to get an initial overview of the data's structure and content.\n",
        "2. **Data Handling Techniques:** We will delve into practical data handling strategies, such as skipping rows or selecting specific columns during the data loading process using parameters like `skiprows` and `usecols` with `read_csv()`.\n",
        "3. **Basic Exploratory Data Analysis (EDA):** We'll perform basic EDA to understand the dataset's characteristics. This includes examining data types, identifying potential missing values, and assessing the overall shape and size of the DataFrame.\n",
        "\n",
        "**Learning Outcomes:**\n",
        "\n",
        "By the end of this lab, you will be proficient in:\n",
        "\n",
        "* Importing and utilizing the Pandas library in Google Colab.\n",
        "* Loading CSV data into a Pandas DataFrame.\n",
        "* Applying data manipulation techniques to extract desired information.\n",
        "* Performing basic EDA to gain insights from datasets."
      ],
      "metadata": {
        "id": "hORGEvrC_cQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Introduction:**\n",
        "Use the pandas read_csv() function to read a CSV file (comma-separated) into a Python pandas DataFrame. which supports options to read any delimited file.\n",
        "\n",
        "##**Dataset:**\n",
        "In this lab we will utilize the dummy employee dataset.\n",
        "\n",
        "[Click here to download employee dataset (employee.csv)](https://drive.google.com/file/d/14RV1xKIRzWS166LtGqnPC1Wg7eTlI_y1/view?usp=drive_link)\n",
        "\n",
        "---\n",
        "\n",
        "# **Begin**\n",
        "\n"
      ],
      "metadata": {
        "id": "NeP9npqTtkH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1: Reading Data from CSVs**\n",
        "\n",
        "Note: if you get error, use the line below:\n",
        "`df = pd.read_csv('employee.csv', on_bad_lines='skip')`\n",
        "\n"
      ],
      "metadata": {
        "id": "NfTyApuouKdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('employee.csv')\n",
        "df\n"
      ],
      "metadata": {
        "id": "_QszDPGZuL4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Use the sep or delimiter argument to specify the separator of the columns. By default, it uses a comma.\n"
      ],
      "metadata": {
        "id": "a4SKIjB5uUgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2: Viewing or Explore your Data**\n",
        "\n",
        "\n",
        "The first thing to do when opening a new dataset is to print out a few rows to keep as a visual reference. We accomplish this with .head():\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UdOcz3nuuXV0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3j5UtRHtRIR"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".head() outputs the first five rows of your DataFrame by default, but we could also pass a number as well. df.head(10) would output the top ten rows.\n"
      ],
      "metadata": {
        "id": "tLPnNeGYucP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "blmNbn3Ou9vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To see the last five rows, use df.tail(), which also accepts a number and prints the bottom two rows in this case.\n",
        "\n"
      ],
      "metadata": {
        "id": "eTH47R-cu52r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(2)"
      ],
      "metadata": {
        "id": "6k7We2FEvBkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 3: Getting Information About your Data**\n",
        "\n",
        ".info() should be one of the very first commands you run after loading your data:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NPOMih5ovKOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "iinLkB4CvMtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**.info()** provides the essential details about your dataset such as the number of rows and columns, the number of non-null values, what type of data is in each column, and how much memory your DataFrame is using.\n",
        "\n",
        "Another fast and useful attribute is .shape, which returns just a tuple of (rows, columns):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RfKs8Y-RvOgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "CLxRE0hrvPk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that .shape has no parentheses and is a simple tuple format (rows, columns). So, we have 15 rows and 4 columns in our employeeDataFrame."
      ],
      "metadata": {
        "id": "wwcgjWC4vaHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 4: Skip Rows**\n",
        "\n",
        "Sometimes, you may need to skip the first row or skip the footer rows. To do this, use skiprows and skipfooter params, respectively.\n",
        "\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "id": "tSjBF23svdDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Skip first few rows\n",
        "df = pd.read_csv('employee.csv', header=None, skiprows=5)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "-GMqnOJ1vepb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 5: Load Only Selected Columns**\n",
        "\n",
        "There are two common ways to use this argument:\n",
        "\n",
        "**Method 1:** Use usecols with Column Names\n",
        "\n",
        "Syntax:\n",
        "`df = pd.read_csv('my_data.csv', usecols=['column name one', 'column name two'])`\n",
        "\n",
        "**Method 2:** Use usecols with Column Positions\n",
        "\n",
        "Syntax:\n",
        "`df = pd.read_csv('my_data.csv', usecols=[0, 2])`\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hooTG_34vhsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('employee.csv', usecols=['Name', 'Salary'])"
      ],
      "metadata": {
        "id": "oHd2BQCPYG__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('employee.csv', usecols =[0,3])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "q0h5NfHOvim8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Submission**\n",
        "- Submit your completed lab using the Start Assignment button on the assignment page in Canvas.\n",
        "- Your submission can be include:\n",
        "  - if you are using notebook then, all tasks should be written and submitted in a single notebook file, for example: (**your_name_labname.ipynb**).\n",
        "  - if you are using python script file, all tasks should be written and submitted in a single python script file for example: **(your_name_labname.py)**.\n",
        "- Add appropriate comments and any additional instructions if required.\n"
      ],
      "metadata": {
        "id": "zDqedojKALa-"
      }
    }
  ]
}