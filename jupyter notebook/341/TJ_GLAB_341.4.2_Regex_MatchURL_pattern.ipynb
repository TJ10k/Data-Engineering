{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16717cdd",
   "metadata": {},
   "source": [
    "# Key Concepts:\n",
    "Regular Expressions: A sequence of characters that define a search pattern, used for pattern matching within text.\n",
    "\n",
    "URL Validation: The process of checking if a URL is syntactically correct and conforms to expected standards.\n",
    "\n",
    "URL Extraction: The process of identifying and extracting URLs from larger text content.\n",
    "\n",
    "Domain Extraction: The process of isolating the domain name (e.g., google.com) from a URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f610323",
   "metadata": {},
   "source": [
    "### Example 1: Validate the URL\n",
    "\n",
    "To match a url pattern, you can use the following regular expression:\n",
    "\n",
    "The given code defines a Python function validate_url(url) that checks if a given URL is valid. It uses a regular expression to validate URLs, and the regular expression pattern is quite complex. \n",
    "\n",
    "The function returns True if the URL is valid and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c1daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to validate a URL\n",
    "def validate_url(url):\n",
    "    # Compile a regular expression pattern for validating URLs\n",
    "    pattern = re.compile( # this is the same thing as (r'^https?://(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\b|(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))(:[0-9]{1,4})?(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "        r'^https?://'  # Match http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+[A-Z]{2,6}\\b|'  # Match domain names\n",
    "        r'(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}'  # Match IP addresses\n",
    "        r'(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?))'  # Match the last segment of the IP\n",
    "        r'(:[0-9]{1,4})?'  # Match optional port numbers\n",
    "        r'(?:/?|[/?]\\S+)$',  # Match optional paths or query strings\n",
    "        re.IGNORECASE  # Make the pattern case insensitive\n",
    "    )\n",
    "    # Return True if the URL matches the pattern, otherwise False\n",
    "    return pattern.match(url) is not None\n",
    "\n",
    "# Test the function with a valid URL\n",
    "print(validate_url(\"http://www.google.com\"))  # Output: True\n",
    "\n",
    "# Test the function with an invalid URL\n",
    "print(validate_url(\"www.google.com\"))  # Output: False\n",
    "\n",
    "print(validate_url(\"https://colab.research.google.com/drive/1PpLud29mzw2EWlGjjg1pd7RIatVJGWUB?usp=sharing#scrollTo=aoLjmV1DJv4b\")) # Extra Test with the link to our GLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d302d6f",
   "metadata": {},
   "source": [
    "### Example 2: Match the URL from the string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs found in the text:\n",
      "\n",
      "/products\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_urls(text):\n",
    "    # Regular expression for matching URLs\n",
    "    url_pattern = r'https?://[a-zA-Z0-9.-]+(/\\S*)?'\n",
    "\n",
    "    # Find all URLs in the text\n",
    "    urls = re.findall(url_pattern, text)\n",
    "\n",
    "    return urls\n",
    "\n",
    "# Sample text containing URLs\n",
    "text = \"Visit my website at https://www.example.com for more information. You can also check http://www.example.org/products\"\n",
    "\n",
    "# Call the function to extract URLs\n",
    "urls = extract_urls(text)\n",
    "\n",
    "# Print the extracted URLs\n",
    "print(\"URLs found in the text:\")\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311b214",
   "metadata": {},
   "source": [
    "This regular expression is used to match URLs. It looks for patterns starting with \"http://\" or \"https://\" followed by a domain part, which consists of alphanumeric characters, dots, and hyphens.\n",
    "\n",
    " It also allows for an optional path and query string (if any) captured by (/\\S*)?. We use re.findall to find all URLs in the given text. The URLs found in the text are then printed.\n",
    "\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "`url_pattern` = ...: This part assigns the regex pattern to a variable named url_pattern for later use.\n",
    "\n",
    "`r'...':` The r' before the opening quote indicates a raw string literal, preventing Python from interpreting backslashes () in the pattern as escape sequences.\n",
    "\n",
    "`https?://:` This matches the beginning of a URL, looking for either \"http://\" or \"https://\". The ? makes the \"s\" in \"https\" optional, allowing for both secure and non-secure URLs.\n",
    "\n",
    "`[a-zA-Z0-9.-]+:` This matches one or more (+) occurrences of any alphanumeric character (a-zA-Z0-9), dot (.), or hyphen (-). This part typically captures the domain name portion of the URL (e.g., \"\n",
    "[redacted link]).\n",
    "\n",
    "`(/\\S*)?:` This part is optional, as indicated by the ? at the end.\n",
    "\n",
    "`(/ ... ):` This group captures the path and query string part of the URL, if present.\n",
    "\n",
    "`\\S*:` This matches zero or more (*) occurrences of any non-whitespace character (\\S). This allows for various path and query string structures (e.g., \"/products\", \"/blog?id=123\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5eb3d3",
   "metadata": {},
   "source": [
    "### Example 3: Match the URL from the string and print URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs found in the text:\n",
      "https://www.example.com\n",
      "\n",
      "Extracted domain names:\n",
      "www.example.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_urls_and_domains(text):\n",
    "    # Regular expression for matching URLs\n",
    "    url_pattern = r'https?://\\S+'\n",
    "\n",
    "    # Regular expression for extracting domain names from URLs\n",
    "    domain_pattern = r'https?://([a-zA-Z0-9.-]+)'\n",
    "\n",
    "    # Find all URLs in the text\n",
    "    urls = re.findall(url_pattern, text)\n",
    "\n",
    "    # Extract domain names from the URLs\n",
    "    # Use re.search to match the domain pattern and extract the first group (domain name)\n",
    "    domains = [re.search(domain_pattern, url).group(1) for url in urls]\n",
    "\n",
    "    return urls, domains\n",
    "\n",
    "# Sample text containing a URL\n",
    "text = \"Visit my website at https://www.example.com for more information.\"\n",
    "\n",
    "# Call the function to extract URLs and domains\n",
    "urls, domains = extract_urls_and_domains(text)\n",
    "\n",
    "# Print the extracted URLs\n",
    "print(\"URLs found in the text:\")\n",
    "for url in urls:\n",
    "    print(url)\n",
    "\n",
    "# Print the extracted domain names\n",
    "print(\"\\nExtracted domain names:\")\n",
    "for domain in domains:\n",
    "    print(domain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
